{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-biotechnology",
   "metadata": {},
   "source": [
    "# Esempi sintetici\n",
    "## Regressione lineare\n",
    "Andiamo a generare e **visualizzare** un semplice dataset monodimensionale, con relazione lineare tra feature e target:\n",
    "\n",
    "$$\n",
    "    f(x) = w_0 + w \\cdot x + \\varepsilon = y\n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "* $w = \\sqrt{2} \\rightarrow$ parametro del modello lineare\n",
    "* $w_0 = -3 \\rightarrow$ intercetta (aka bias)\n",
    "* $x \\in \\mathcal{U}[-10, 10] \\rightarrow$ unica feature osservata\n",
    "* $y \\rightarrow$ variabile target\n",
    "* $\\varepsilon \\sim \\mathcal{N}(0, 3)$ √® una modellazione di [rumore additivo gaussiano](https://en.wikipedia.org/wiki/Additive_white_Gaussian_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "low = -10\n",
    "high = 10\n",
    "\n",
    "data = pd.DataFrame({'x': (high - low) * np.random.random_sample(n_samples) + low})\n",
    "w = np.array([-3, np.sqrt(2)])\n",
    "noise = 3 * np.random.randn(n_samples)\n",
    "\n",
    "def f(x, w):\n",
    "    return w[0] + w[1]*x\n",
    "\n",
    "data['y'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-cricket",
   "metadata": {},
   "source": [
    "Andiamo ora a campionare uniformemente il dominio di $x$, e calcoliamone la $y$ associata (teorica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.DataFrame({'x': np.linspace(data['x'].min(), data['x'].max())})\n",
    "clean_data['y'] = ...\n",
    "\n",
    "ax = plt.figure(dpi=100).gca()\n",
    "data.plot(x='x', y='y', kind='scatter', label='data', ax=ax)\n",
    "clean_data.plot(x='x', y='y', label=f'f(x) = -3 + ‚àö2 x', color='C1', ax=ax)\n",
    "plt.xlabel('input feature')\n",
    "plt.ylabel('output target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-malaysia",
   "metadata": {},
   "source": [
    "Il nostro scopo sar√† quello di **quantificare** i parametri del modello ($w \\approx \\sqrt{2}$ e $w_0 \\approx -3$), a partire dai dati. Per fare ci√≤ sfrutteremo una library di ML molto potente: [`scikit-learn`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = ...\n",
    "\n",
    "print(f\"w_0: stima {model.intercept_[0]} | vero {w[0]}\")\n",
    "print(f\"w: stima {model.coef_[0][0]} | vero {w[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-siemens",
   "metadata": {},
   "source": [
    "Andiamo quindi ad applicare il nostro modello sul dominio della $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ...\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-portugal",
   "metadata": {},
   "source": [
    "Andiamo ad aggiungere il nostro modello al plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(dpi=100).gca()\n",
    "data.plot(x='x', y='y', kind='scatter', label='data', ax=ax)\n",
    "clean_data.plot(x='x', y='y', label=f'f(x) = -3 + ‚àö2 x', color='C1', ax=ax)\n",
    "plt.plot(clean_data[['x']].values, y_pred, '--', label=r\"$\\hat{f}$\" + f\"(x) = {model.intercept_[0]:.2f} + {model.coef_[0][0]:.2f} x\", color='C2')\n",
    "plt.xlabel('input feature')\n",
    "plt.ylabel('output target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-chorus",
   "metadata": {},
   "source": [
    "## Quando la regressione lineare non basta?\n",
    "Ripetiamo l'esempio precedente, ma introducendo una relazione non lineare tra input ed output.\n",
    "\n",
    "$$\n",
    "    f(x) = w_0 + \\cos(\\pi w \\cdot x) + \\varepsilon = y\n",
    "$$\n",
    "\n",
    "dove:\n",
    "* $w = \\sqrt{2} \\rightarrow$ parametro del modello non lineare\n",
    "* $w_0 = -3 \\rightarrow$ intercetta (aka bias)\n",
    "* $x \\in \\mathcal{U}[0, 2] \\rightarrow$ unica feature osservata (‚ö†Ô∏è dominio differente rispetto a prima)\n",
    "* $y \\rightarrow$ variabile target\n",
    "* $\\varepsilon \\sim \\mathcal{N}(0, 0.33)$ √® una modellazione di [rumore additivo gaussiano](https://en.wikipedia.org/wiki/Additive_white_Gaussian_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, w):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'x': 2 * np.random.rand(n_samples)})\n",
    "w = np.array([-3, np.sqrt(2)])\n",
    "noise =  .33 * np.random.randn(n_samples)\n",
    "\n",
    "data['y'] = ...\n",
    "\n",
    "clean_data = pd.DataFrame({'x': np.linspace(data['x'].min(), data['x'].max())})\n",
    "clean_data['y'] = ...\n",
    "\n",
    "ax = plt.figure(dpi=100).gca()\n",
    "data.plot(x='x', y='y', kind='scatter', label='data', ax=ax)\n",
    "clean_data.plot(x='x', y='y', label='f(x) = -3 + cos(œÄ ‚àö2 x)', color='C1', ax=ax)\n",
    "plt.xlabel('input feature')\n",
    "plt.ylabel('output target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-samoa",
   "metadata": {},
   "source": [
    "Ripetiamo i passi precedenti, ed applichiamo un modello lineare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "y_pred = ...\n",
    "\n",
    "ax = plt.figure(dpi=100).gca()\n",
    "data.plot(x='x', y='y', kind='scatter', label='data', ax=ax)\n",
    "clean_data.plot(x='x', y='y', label='f(x) = -3 + cos(œÄ ‚àö2 x)', color='C1', ax=ax)\n",
    "plt.plot(clean_data['x'].values, y_pred, '--', color='C2', label=f'f(x) = {model.intercept_[0]:.2f} + {model.coef_[0][0]:.2f} x')\n",
    "plt.xlabel('input feature')\n",
    "plt.ylabel('output target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-wound",
   "metadata": {},
   "source": [
    "Il modello non approssima correttamente la relazione input/output: siamo in un caso di _underfit_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-robertson",
   "metadata": {},
   "source": [
    "## Cambiamo il punto di vista\n",
    "Invece di cercare di approssimare la relazione input/output con un modello parametrico, proviamo un approccio non parametrico: [decision tree](https://scikit-learn.org/stable/modules/tree.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = ...\n",
    "y_pred = ...\n",
    "\n",
    "ax = plt.figure(dpi=100).gca()\n",
    "data.plot(x='x', y='y', kind='scatter', label='data', ax=ax)\n",
    "clean_data.plot(x='x', y='y', label='f(x) = -3 + cos(œÄ ‚àö2 x)', color='C1', ax=ax)\n",
    "plt.plot(clean_data['x'].values, y_pred, '--', color='C2', label=f'decision tree')\n",
    "plt.xlabel('input feature')\n",
    "plt.ylabel('output target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-mayor",
   "metadata": {},
   "source": [
    "Il modello insegue molto bene i dati, anche troppo: siamo in un caso di _overfit_.\n",
    "\n",
    "Trovare il giusto trade-off tra _underfit_ ed _overfit_ √® detto **model tuning**, ed √® uno dei principali ostacoli che incontreremo allenando modelli di ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "y_pred = ...\n",
    "\n",
    "ax = plt.figure(dpi=100).gca()\n",
    "data.plot(x='x', y='y', kind='scatter', label='data', ax=ax)\n",
    "clean_data.plot(x='x', y='y', label='f(x) = -3 + cos(œÄ ‚àö2 x)', color='C1', ax=ax)\n",
    "plt.plot(clean_data['x'].values, y_pred, '--', color='C2', label=f'decision tree')\n",
    "plt.xlabel('input feature')\n",
    "plt.ylabel('output target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-contemporary",
   "metadata": {},
   "source": [
    "# Use case reale: `MiMocko`\n",
    "**Domanda business**: fornire alert agli utenti in fase di noleggio se la batteria rischia di non reggere la durata del viaggio indicato.\n",
    "\n",
    "$$\n",
    "    \\downarrow\n",
    "$$\n",
    "\n",
    "**ML task**: allenare un modello di _regressione_ che risolva il seguente problema: `f(dati di viaggio) ‚âà carica batteria termine`.\n",
    "\n",
    "## Caricamento e preparazione dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = '../../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "viaggi = pd.read_csv(\n",
    "    f'{path_to_file}/viaggi.csv',\n",
    "    sep='*',\n",
    "    decimal=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "viaggi.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-accounting",
   "metadata": {},
   "source": [
    "## Selezioniamo solo le colonne _interessanti_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ...\n",
    "data = viaggi[columns]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-lightning",
   "metadata": {},
   "source": [
    "## Abbiamo presenza di valori mancanti?\n",
    "Se s√¨, scegliamo di eliminare le righe corrispondenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(data).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-isolation",
   "metadata": {},
   "source": [
    "**(BONUS)** per gestire valori mancanti √® anche possibile utilizzare il modulo [`sklearn.impute`](https://scikit-learn.org/stable/modules/impute.html).\n",
    "\n",
    "## Preprocessiamo i dati e prepariamo il nostro learning set\n",
    "Di che tipo sono le colonne estratte? Sono pronte per essere analizzate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessiamo i dati, colonna per colonna\n",
    "data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-convergence",
   "metadata": {},
   "source": [
    "## Data exploration (minimale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8, 6)).gca()\n",
    "data.hist(ax=ax)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-footage",
   "metadata": {},
   "source": [
    "## Separiamo le _features_ dal _target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ...\n",
    "features = ...\n",
    "\n",
    "print(target)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = data[features]\n",
    "dfy = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-monkey",
   "metadata": {},
   "source": [
    "## Train/Test split\n",
    "üî• Fase **fondamentale** per capire quanto bene il nostro modello possa funzionare in produzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfX, dfy, test_size=0.33)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-angel",
   "metadata": {},
   "source": [
    "Quanto sono grandi i due set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-nepal",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "### Training\n",
    "Alleniamo un modello linere ed otteniamo una rappresentazione del tipo:\n",
    "\n",
    "`target = bias + w_1 * feat_1 + w_2 * feat_2 + ... `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = ...\n",
    "\n",
    "# Stampiamo l'equazione del modello sotto forma di stringa\n",
    "equation = ...\n",
    "print(equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-resort",
   "metadata": {},
   "source": [
    "## Assessment\n",
    "Analizziamo il Mean Absolute Error ([MAE](https://en.wikipedia.org/wiki/Mean_absolute_error)) ed il Coefficient of determination ([R2](https://en.wikipedia.org/wiki/Coefficient_of_determination))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_train_pred = ...\n",
    "\n",
    "print('Train scores')\n",
    "print(f\"MAE = {metrics.mean_absolute_error(y_train, y_train_pred):.3f}\")\n",
    "print(f\"R2 = {metrics.r2_score(y_train, y_train_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ...\n",
    "\n",
    "print('Test scores')\n",
    "print(f\"MAE = {metrics.mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "print(f\"R2 = {metrics.r2_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-mandate",
   "metadata": {},
   "source": [
    "Cosa possiamo concludere?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-interference",
   "metadata": {},
   "source": [
    "## Decision tree\n",
    "### Training\n",
    "\n",
    "Alleniamo il modello ed osserviamo le regole imparate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = ...\n",
    "\n",
    "# Stampiamo le regole imparate del modello sotto forma di stringa\n",
    "n_rows = 15\n",
    "print('\\n'.join(tree.export_text(model, feature_names=features).split('\\n')[:n_rows]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-violation",
   "metadata": {},
   "source": [
    "**(BONUS)** per alberi/dataset _relativamente_ piccoli, √® possibile ottenere una rappresentazione grafica con [`dtreeviz`](https://github.com/parrt/dtreeviz).\n",
    "\n",
    "```python\n",
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "viz = dtreeviz(model, X_train, y_train,\n",
    "               target_name=target,\n",
    "               feature_names=features)\n",
    "\n",
    "viz.save(\"decision_tree.svg\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-object",
   "metadata": {},
   "source": [
    "## Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = ...\n",
    "\n",
    "print('Train scores')\n",
    "print(f\"MAE = {metrics.mean_absolute_error(y_train, y_train_pred):.3f}\")\n",
    "print(f\"R2 = {metrics.r2_score(y_train, y_train_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ...\n",
    "\n",
    "print('Test scores')\n",
    "print(f\"MAE = {metrics.mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "print(f\"R2 = {metrics.r2_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-draft",
   "metadata": {},
   "source": [
    "Cosa possiamo concludere?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-routine",
   "metadata": {},
   "source": [
    "# (Bonus) Hyperparameter tuning\n",
    "Al contrario della semplice regressione lineare, l'albero decisionale ha un parametro importante: la profondit√†. Scriviamo una pipeline automatica per ottimizzarne il valore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = RandomizedSearchCV(estimator=tree.DecisionTreeRegressor(),\n",
    "                           param_distributions={'max_depth': stats.randint(2, 50)},\n",
    "                           n_iter=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "print('Train scores')\n",
    "print(f\"MAE = {metrics.mean_absolute_error(y_train, y_train_pred):.3f}\")\n",
    "print(f\"R2 = {metrics.r2_score(y_train, y_train_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Test scores')\n",
    "print(f\"MAE = {metrics.mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "print(f\"R2 = {metrics.r2_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-cursor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
